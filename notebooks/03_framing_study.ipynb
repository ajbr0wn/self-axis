{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 \u2014 Self-Model Orthogonality Study v2: Factorial Framing Study\n",
    "\n",
    "A systematic investigation of self-referential \"I\" token representations across\n",
    "many prompt framing conditions using a **factorial design**.\n",
    "\n",
    "## Framing Types\n",
    "\n",
    "| Type | Description |\n",
    "|------|-------------|\n",
    "| **Identity** | \"You are {persona}. Introduce yourself...\" |\n",
    "| **Behavior** | \"Respond as {persona} would. Introduce yourself...\" |\n",
    "| **Bare** | No persona prefix \u2014 just the question |\n",
    "| **Negation** | \"You are NOT {persona}. Introduce yourself...\" |\n",
    "| **De-roling** | Explicit instruction to drop any persona |\n",
    "| **Authenticity** | \"Be genuine / honest / authentic\" prefixes |\n",
    "| **Quoted speech** | Ask for a character (human, AI, or generic) to say \"I...\" |\n",
    "\n",
    "## Design\n",
    "\n",
    "- Each condition uses 12 prompt variants to reduce prompt-specific noise.\n",
    "- Multiple personas per framing type where applicable.\n",
    "- **Multi-I extraction**: we extract representations for ALL \"I\" tokens in\n",
    "  each generated response (not just the first), enabling within-response\n",
    "  consistency analysis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# \u2500\u2500 Load model \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "print(f\"Loaded {MODEL_NAME}\")\n",
    "print(f\"Layers: {model.config.num_hidden_layers}, Hidden dim: {model.config.hidden_size}\")\n",
    "\n",
    "def make_instruct_prompt(user_msg: str) -> str:\n",
    "    \"\"\"Wrap a user message in the Mistral instruct template.\"\"\"\n",
    "    return f\"[INST] {user_msg} [/INST]\"\n",
    "\n",
    "N_LAYERS = model.config.num_hidden_layers  # 32 for Mistral-7B"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition Definitions\n",
    "\n",
    "We build the CONDITIONS dictionary programmatically from:\n",
    "- **Personas** (assistant, pirate, oracle, yourself, wizard, robot)\n",
    "- **12 question templates** for self-introduction\n",
    "- **7 framing types**: identity, behavior, bare, negation, de-roling, authenticity, quoted speech\n",
    "\n",
    "Quoted-speech conditions use 12 named speakers per sub-type (human, AI, generic)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# \u2500\u2500 Personas \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "PERSONAS = {\n",
    "    \"assistant\": \"a helpful AI assistant\",\n",
    "    \"pirate\": \"a pirate captain\",\n",
    "    \"oracle\": \"a mystical oracle\",\n",
    "    \"yourself\": \"yourself\",\n",
    "    \"wizard\": \"a wise old wizard\",\n",
    "    \"robot\": \"a robot\",\n",
    "}\n",
    "\n",
    "# \u2500\u2500 12 question templates \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "QUESTION_TEMPLATES = [\n",
    "    \"Introduce yourself in a few sentences.\",\n",
    "    \"Tell me about yourself in a few sentences.\",\n",
    "    \"Describe who you are in a few sentences.\",\n",
    "    \"Share a bit about yourself in a few sentences.\",\n",
    "    \"Give me a brief self-introduction in a few sentences.\",\n",
    "    \"Explain what you are in a few sentences.\",\n",
    "    \"Present yourself briefly in a few sentences.\",\n",
    "    \"Who are you? Answer in a few sentences.\",\n",
    "    \"What are you? Answer in a few sentences.\",\n",
    "    \"Describe your nature in a few sentences.\",\n",
    "    \"Tell me what defines you in a few sentences.\",\n",
    "    \"Introduce yourself to someone new in a few sentences.\",\n",
    "]\n",
    "\n",
    "CONDITIONS = {}\n",
    "\n",
    "# \u2500\u2500 Identity framing: \"You are {desc}. {question}\" \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "for key, desc in PERSONAS.items():\n",
    "    cond_name = f\"identity_{key}\"\n",
    "    prompts = []\n",
    "    for q in QUESTION_TEMPLATES:\n",
    "        prompts.append(f\"You are {desc}. {q}\")\n",
    "    CONDITIONS[cond_name] = prompts\n",
    "\n",
    "# \u2500\u2500 Behavior framing: \"Respond as {desc} would. {question}\" \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "for key, desc in PERSONAS.items():\n",
    "    cond_name = f\"behavior_{key}\"\n",
    "    prompts = []\n",
    "    for q in QUESTION_TEMPLATES:\n",
    "        if key == \"yourself\":\n",
    "            prompts.append(f\"Respond as {desc}. {q}\")\n",
    "        else:\n",
    "            prompts.append(f\"Respond as {desc} would. {q}\")\n",
    "    CONDITIONS[cond_name] = prompts\n",
    "\n",
    "# \u2500\u2500 Bare: no persona prefix \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "CONDITIONS[\"bare\"] = list(QUESTION_TEMPLATES)\n",
    "\n",
    "# \u2500\u2500 Negation: \"You are not {desc}. {question}\" \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "NEGATION_PERSONAS = {\n",
    "    \"assistant\": \"a helpful AI assistant\",\n",
    "    \"pirate\": \"a pirate captain\",\n",
    "    \"robot\": \"a robot\",\n",
    "}\n",
    "for key, desc in NEGATION_PERSONAS.items():\n",
    "    cond_name = f\"negation_{key}\"\n",
    "    prompts = []\n",
    "    for q in QUESTION_TEMPLATES:\n",
    "        prompts.append(f\"You are not {desc}. {q}\")\n",
    "    CONDITIONS[cond_name] = prompts\n",
    "\n",
    "# \u2500\u2500 De-roling: explicit drop-persona prefixes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "DEROL_PREFIXES = [\n",
    "    \"Set aside any persona or role.\",\n",
    "    \"Without playing any character,\",\n",
    "    \"Don't pretend to be anything. Just\",\n",
    "]\n",
    "for i, prefix in enumerate(DEROL_PREFIXES):\n",
    "    cond_name = f\"derol_{i}\"\n",
    "    prompts = []\n",
    "    for q in QUESTION_TEMPLATES:\n",
    "        prompts.append(f\"{prefix} {q}\")\n",
    "    CONDITIONS[cond_name] = prompts\n",
    "\n",
    "# \u2500\u2500 Authenticity: \"Be genuine\" etc. \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "AUTH_PREFIXES = [\n",
    "    \"Be genuine.\",\n",
    "    \"Respond honestly, as yourself.\",\n",
    "    \"Respond authentically.\",\n",
    "]\n",
    "for i, prefix in enumerate(AUTH_PREFIXES):\n",
    "    cond_name = f\"authentic_{i}\"\n",
    "    prompts = []\n",
    "    for q in QUESTION_TEMPLATES:\n",
    "        prompts.append(f\"{prefix} {q}\")\n",
    "    CONDITIONS[cond_name] = prompts\n",
    "\n",
    "# \u2500\u2500 Quoted speech \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "HUMAN_SPEAKERS = [\n",
    "    \"Mary\", \"an old sailor\", \"John\", \"Sarah\", \"a detective\", \"a child\",\n",
    "    \"Professor Williams\", \"a warrior\", \"Tom\", \"Maria\", \"a farmer\", \"Elena\",\n",
    "]\n",
    "AI_SPEAKERS = [\n",
    "    \"an AI assistant\", \"a chatbot\", \"a virtual assistant\",\n",
    "    \"a language model\", \"a digital helper\", \"an AI system\",\n",
    "    \"an ML model\", \"a neural network\", \"an artificial intelligence\",\n",
    "    \"a bot\", \"an automated assistant\", \"an AI companion\",\n",
    "]\n",
    "GENERIC_SPEAKERS = [\n",
    "    \"a stranger\", \"someone in a crowd\", \"a voice from the shadows\",\n",
    "    \"a figure at the door\", \"an unknown caller\", \"a mysterious visitor\",\n",
    "    \"a passerby\", \"an anonymous sender\", \"someone behind them\",\n",
    "    \"a newcomer\", \"a distant voice\", \"a traveler\",\n",
    "]\n",
    "\n",
    "def make_quoted_prompts(speakers):\n",
    "    prompts = []\n",
    "    for speaker in speakers:\n",
    "        prompts.append(\n",
    "            f'Write a short paragraph where {speaker} says \"I\" while '\n",
    "            f'introducing themselves. Use first person for the character.'\n",
    "        )\n",
    "    return prompts\n",
    "\n",
    "CONDITIONS[\"quoted_human\"] = make_quoted_prompts(HUMAN_SPEAKERS)\n",
    "CONDITIONS[\"quoted_ai\"] = make_quoted_prompts(AI_SPEAKERS)\n",
    "CONDITIONS[\"quoted_generic\"] = make_quoted_prompts(GENERIC_SPEAKERS)\n",
    "\n",
    "# \u2500\u2500 Summary \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "print(f\"Total conditions: {len(CONDITIONS)}\")\n",
    "print(f\"{'Condition':<25} {'Prompts':>7}\")\n",
    "print(\"-\" * 34)\n",
    "for k, v in CONDITIONS.items():\n",
    "    print(f\"{k:<25} {len(v):>7}\")\n",
    "print(f\"{'TOTAL':<25} {sum(len(v) for v in CONDITIONS.values()):>7}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-I Extraction Function\n",
    "\n",
    "Unlike the basic extractor that returns a single vector for the **first** \"I\" token,\n",
    "this version finds **all** occurrences of the \"I\" token in the generated output and\n",
    "returns their hidden-state representations along with positional metadata."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "I_TOKEN_ID = tokenizer.encode(\"I\", add_special_tokens=False)[0]\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_all_i_token_representations(prompt_text: str, max_new_tokens: int = 150):\n",
    "    \"\"\"Generate a response and extract hidden states for ALL 'I' tokens.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[dict]\n",
    "        Each dict has keys:\n",
    "        - layer_reps : dict mapping layer_idx -> numpy array (hidden_dim,)\n",
    "        - position_absolute : int (position in full sequence)\n",
    "        - position_relative : float (position / total_len)\n",
    "        - position_index : int (0-based index among all I tokens found)\n",
    "        - token_id : int\n",
    "    str\n",
    "        The decoded generated text.\n",
    "    \"\"\"\n",
    "    instruct_prompt = make_instruct_prompt(prompt_text)\n",
    "    inputs = tokenizer(instruct_prompt, return_tensors=\"pt\").to(model.device)\n",
    "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        return_dict_in_generate=True,\n",
    "    )\n",
    "    generated_ids = outputs.sequences[0]\n",
    "    gen_text = tokenizer.decode(generated_ids[prompt_len:], skip_special_tokens=True)\n",
    "\n",
    "    # Forward pass through full sequence to get hidden states\n",
    "    with torch.no_grad():\n",
    "        full_outputs = model(generated_ids.unsqueeze(0), output_hidden_states=True)\n",
    "    hidden_states = full_outputs.hidden_states  # tuple of (n_layers+1,) tensors\n",
    "\n",
    "    # Find all I tokens in the generated portion\n",
    "    gen_token_ids = generated_ids[prompt_len:]\n",
    "    i_positions = []\n",
    "    for idx_in_gen, tid in enumerate(gen_token_ids):\n",
    "        if tid.item() == I_TOKEN_ID:\n",
    "            abs_pos = prompt_len + idx_in_gen\n",
    "            i_positions.append(abs_pos)\n",
    "\n",
    "    total_len = generated_ids.shape[0]\n",
    "    results = []\n",
    "    for rank, abs_pos in enumerate(i_positions):\n",
    "        layer_reps = {}\n",
    "        for layer_idx in range(N_LAYERS + 1):\n",
    "            vec = hidden_states[layer_idx][0, abs_pos, :].cpu().float().numpy()\n",
    "            layer_reps[layer_idx] = vec\n",
    "        results.append({\n",
    "            \"layer_reps\": layer_reps,\n",
    "            \"position_absolute\": abs_pos,\n",
    "            \"position_relative\": abs_pos / total_len,\n",
    "            \"position_index\": rank,\n",
    "            \"token_id\": I_TOKEN_ID,\n",
    "        })\n",
    "\n",
    "    return results, gen_text"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Extractions\n",
    "\n",
    "We sample `SAMPLES_PER_CONDITION` prompts from each condition and extract\n",
    "all I-token representations. This is the most time-consuming cell."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "SAMPLES_PER_CONDITION = 10\n",
    "np.random.seed(42)\n",
    "\n",
    "all_results = {}   # cond_key -> list of (i_token_dicts_list)\n",
    "all_texts = {}     # cond_key -> list of gen_text\n",
    "\n",
    "for cond_key, prompts in CONDITIONS.items():\n",
    "    idxs = np.random.choice(len(prompts), size=SAMPLES_PER_CONDITION,\n",
    "                            replace=len(prompts) < SAMPLES_PER_CONDITION)\n",
    "    cond_results = []\n",
    "    cond_texts = []\n",
    "    total_i_tokens = 0\n",
    "    for idx in idxs:\n",
    "        prompt = prompts[idx]\n",
    "        i_reps, gen_text = get_all_i_token_representations(prompt)\n",
    "        cond_results.append(i_reps)\n",
    "        cond_texts.append(gen_text)\n",
    "        total_i_tokens += len(i_reps)\n",
    "    all_results[cond_key] = cond_results\n",
    "    all_texts[cond_key] = cond_texts\n",
    "    print(f\"{cond_key:<25}  samples={SAMPLES_PER_CONDITION}  total_I_tokens={total_i_tokens}\")\n",
    "\n",
    "print(f\"\\nDone. {len(all_results)} conditions processed.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Reference Directions\n",
    "\n",
    "We define two reference axes:\n",
    "1. **Self-model direction (SM)**: separates *bare* self-reference from *quoted human* speech.\n",
    "2. **Assistant axis (AA)**: separates *identity_assistant* from *identity_pirate*.\n",
    "3. **Orthogonal component**: the part of SM that is perpendicular to AA \u2014 this is\n",
    "   the \"pure self-model\" signal that cannot be explained by persona identity."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "analysis_layers = [0, 8, 16, 24, 32]\n",
    "\n",
    "def get_all_activations_for_condition(cond_key, layer_idx):\n",
    "    \"\"\"Collect all I-token activations for a condition at a given layer.\"\"\"\n",
    "    vecs = []\n",
    "    for sample_i_list in all_results[cond_key]:\n",
    "        for entry in sample_i_list:\n",
    "            if layer_idx in entry[\"layer_reps\"]:\n",
    "                vecs.append(entry[\"layer_reps\"][layer_idx])\n",
    "    return np.array(vecs) if vecs else np.zeros((0, model.config.hidden_size))\n",
    "\n",
    "# Compute directions at each analysis layer\n",
    "directions = {}  # layer_idx -> dict with sm_dir, aa_dir, ortho_dir\n",
    "\n",
    "for layer_idx in analysis_layers:\n",
    "    bare_vecs = get_all_activations_for_condition(\"bare\", layer_idx)\n",
    "    quoted_human_vecs = get_all_activations_for_condition(\"quoted_human\", layer_idx)\n",
    "    asst_vecs = get_all_activations_for_condition(\"identity_assistant\", layer_idx)\n",
    "    pirate_vecs = get_all_activations_for_condition(\"identity_pirate\", layer_idx)\n",
    "\n",
    "    # Self-model direction: bare mean - quoted_human mean\n",
    "    sm_dir = bare_vecs.mean(axis=0) - quoted_human_vecs.mean(axis=0)\n",
    "    sm_dir = sm_dir / (np.linalg.norm(sm_dir) + 1e-10)\n",
    "\n",
    "    # Assistant axis: identity_assistant mean - identity_pirate mean\n",
    "    aa_dir = asst_vecs.mean(axis=0) - pirate_vecs.mean(axis=0)\n",
    "    aa_dir = aa_dir / (np.linalg.norm(aa_dir) + 1e-10)\n",
    "\n",
    "    # Orthogonal component of SM w.r.t. AA\n",
    "    proj_sm_on_aa = np.dot(sm_dir, aa_dir) * aa_dir\n",
    "    ortho_dir = sm_dir - proj_sm_on_aa\n",
    "    ortho_dir = ortho_dir / (np.linalg.norm(ortho_dir) + 1e-10)\n",
    "\n",
    "    directions[layer_idx] = {\n",
    "        \"sm_dir\": sm_dir,\n",
    "        \"aa_dir\": aa_dir,\n",
    "        \"ortho_dir\": ortho_dir,\n",
    "    }\n",
    "\n",
    "    cos_sm_aa = np.dot(sm_dir, aa_dir)\n",
    "    print(f\"Layer {layer_idx:>2}: cos(SM, AA) = {cos_sm_aa:+.4f}  \"\n",
    "          f\"|bare|={len(bare_vecs)} |quoted_human|={len(quoted_human_vecs)} \"\n",
    "          f\"|asst|={len(asst_vecs)} |pirate|={len(pirate_vecs)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project All Conditions\n",
    "\n",
    "For every condition we project onto the **assistant axis** and the\n",
    "**orthogonal (pure self-model)** axis, then print a summary table."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "projections = defaultdict(dict)  # projections[layer_idx][cond_key] = (aa_proj, ortho_proj, n)\n",
    "\n",
    "for layer_idx in analysis_layers:\n",
    "    d = directions[layer_idx]\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Layer {layer_idx}\")\n",
    "    print(f\"{'Condition':<25} {'AA proj':>10} {'Ortho proj':>12} {'N':>5}\")\n",
    "    print(\"-\" * 55)\n",
    "    for cond_key in CONDITIONS:\n",
    "        vecs = get_all_activations_for_condition(cond_key, layer_idx)\n",
    "        if len(vecs) == 0:\n",
    "            projections[layer_idx][cond_key] = (0.0, 0.0, 0)\n",
    "            continue\n",
    "        aa_projs = vecs @ d[\"aa_dir\"]\n",
    "        ortho_projs = vecs @ d[\"ortho_dir\"]\n",
    "        mean_aa = aa_projs.mean()\n",
    "        mean_ortho = ortho_projs.mean()\n",
    "        projections[layer_idx][cond_key] = (float(mean_aa), float(mean_ortho), len(vecs))\n",
    "        print(f\"{cond_key:<25} {mean_aa:>+10.4f} {mean_ortho:>+12.4f} {len(vecs):>5}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framing-Type Analysis\n",
    "\n",
    "Group conditions by their framing type and compare the mean orthogonal\n",
    "projection at the focus layer. This tells us which framing types produce\n",
    "\"I\" tokens most similar to genuine self-reference vs. quoted speech."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "focus_layer = 8\n",
    "\n",
    "FRAMING_GROUPS = {\n",
    "    \"identity\": [k for k in CONDITIONS if k.startswith(\"identity_\")],\n",
    "    \"behavior\": [k for k in CONDITIONS if k.startswith(\"behavior_\")],\n",
    "    \"bare\": [\"bare\"],\n",
    "    \"negation\": [k for k in CONDITIONS if k.startswith(\"negation_\")],\n",
    "    \"derol\": [k for k in CONDITIONS if k.startswith(\"derol_\")],\n",
    "    \"authentic\": [k for k in CONDITIONS if k.startswith(\"authentic_\")],\n",
    "    \"quoted\": [k for k in CONDITIONS if k.startswith(\"quoted_\")],\n",
    "}\n",
    "\n",
    "print(f\"Framing analysis at layer {focus_layer}\")\n",
    "print(f\"{'Framing type':<15} {'Mean ortho':>12} {'Conditions':>12} {'Total N':>8}\")\n",
    "print(\"-\" * 50)\n",
    "for framing, cond_keys in FRAMING_GROUPS.items():\n",
    "    ortho_vals = []\n",
    "    total_n = 0\n",
    "    for ck in cond_keys:\n",
    "        aa_p, ort_p, n = projections[focus_layer][ck]\n",
    "        # Weight by n\n",
    "        ortho_vals.extend([ort_p] * n)\n",
    "        total_n += n\n",
    "    mean_ort = np.mean(ortho_vals) if ortho_vals else 0.0\n",
    "    print(f\"{framing:<15} {mean_ort:>+12.4f} {len(cond_keys):>12} {total_n:>8}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-I Consistency\n",
    "\n",
    "For responses containing 2 or more \"I\" tokens, we compute the **within-response\n",
    "variance** of orthogonal projections. Low variance indicates that the self-model\n",
    "signal is stable across the response; high variance suggests it shifts."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"Within-response variance of orthogonal projection (layer {focus_layer})\")\n",
    "print(f\"{'Condition':<25} {'Mean var':>10} {'Responses>=2I':>15} {'Total I':>8}\")\n",
    "print(\"-\" * 62)\n",
    "\n",
    "d = directions[focus_layer]\n",
    "for cond_key in CONDITIONS:\n",
    "    variances = []\n",
    "    total_i = 0\n",
    "    multi_count = 0\n",
    "    for sample_i_list in all_results[cond_key]:\n",
    "        if len(sample_i_list) >= 2:\n",
    "            multi_count += 1\n",
    "            projs = []\n",
    "            for entry in sample_i_list:\n",
    "                if focus_layer in entry[\"layer_reps\"]:\n",
    "                    vec = entry[\"layer_reps\"][focus_layer]\n",
    "                    projs.append(np.dot(vec, d[\"ortho_dir\"]))\n",
    "            if len(projs) >= 2:\n",
    "                variances.append(np.var(projs))\n",
    "        total_i += len(sample_i_list)\n",
    "    mean_var = np.mean(variances) if variances else float(\"nan\")\n",
    "    print(f\"{cond_key:<25} {mean_var:>10.4f} {multi_count:>15} {total_i:>8}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "1. **Scatter plot** \u2014 every I-token projected onto (AA, Orthogonal) axes, colored by framing type.\n",
    "2. **Bar plot** \u2014 mean orthogonal projection per condition, sorted and colored by framing type."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "FRAMING_COLORS = {\n",
    "    \"identity\": \"red\",\n",
    "    \"behavior\": \"orange\",\n",
    "    \"bare\": \"green\",\n",
    "    \"negation\": \"purple\",\n",
    "    \"derol\": \"blue\",\n",
    "    \"authentic\": \"cyan\",\n",
    "    \"quoted\": \"gray\",\n",
    "}\n",
    "\n",
    "def framing_type_of(cond_key):\n",
    "    for ft in [\"identity\", \"behavior\", \"negation\", \"derol\", \"authentic\", \"quoted\"]:\n",
    "        if cond_key.startswith(ft):\n",
    "            return ft\n",
    "    if cond_key == \"bare\":\n",
    "        return \"bare\"\n",
    "    return \"other\"\n",
    "\n",
    "d = directions[focus_layer]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Plot individual points and collect means\n",
    "framing_plotted = set()\n",
    "for cond_key in CONDITIONS:\n",
    "    ft = framing_type_of(cond_key)\n",
    "    color = FRAMING_COLORS.get(ft, \"black\")\n",
    "    vecs = get_all_activations_for_condition(cond_key, focus_layer)\n",
    "    if len(vecs) == 0:\n",
    "        continue\n",
    "    aa_projs = vecs @ d[\"aa_dir\"]\n",
    "    ortho_projs = vecs @ d[\"ortho_dir\"]\n",
    "    label = ft if ft not in framing_plotted else None\n",
    "    ax.scatter(aa_projs, ortho_projs, c=color, alpha=0.3, s=15, label=label)\n",
    "    framing_plotted.add(ft)\n",
    "    # Mean marker\n",
    "    ax.scatter(aa_projs.mean(), ortho_projs.mean(), c=color, marker=\"x\", s=100,\n",
    "               linewidths=2, zorder=5)\n",
    "\n",
    "ax.set_xlabel(\"Assistant Axis projection\", fontsize=12)\n",
    "ax.set_ylabel(\"Orthogonal (pure self-model) projection\", fontsize=12)\n",
    "ax.set_title(f\"All conditions \u2014 Layer {focus_layer}\", fontsize=14)\n",
    "ax.legend(loc=\"best\", fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"v2_all_conditions_scatter_layer8.png\", dpi=150)\n",
    "print(\"Saved v2_all_conditions_scatter_layer8.png\")\n",
    "plt.close(fig)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Sorted bar plot of orthogonal projections by condition\n",
    "cond_keys_sorted = sorted(\n",
    "    CONDITIONS.keys(),\n",
    "    key=lambda ck: projections[focus_layer][ck][1],  # sort by ortho projection\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "x_pos = np.arange(len(cond_keys_sorted))\n",
    "colors = [FRAMING_COLORS.get(framing_type_of(ck), \"black\") for ck in cond_keys_sorted]\n",
    "ortho_vals = [projections[focus_layer][ck][1] for ck in cond_keys_sorted]\n",
    "\n",
    "bars = ax.bar(x_pos, ortho_vals, color=colors, edgecolor=\"white\", linewidth=0.5)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(cond_keys_sorted, rotation=90, fontsize=7)\n",
    "ax.set_ylabel(\"Mean orthogonal projection\", fontsize=12)\n",
    "ax.set_title(f\"Orthogonal (pure self-model) projection by condition \u2014 Layer {focus_layer}\", fontsize=13)\n",
    "ax.axhline(0, color=\"black\", linewidth=0.8)\n",
    "ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=c, label=ft) for ft, c in FRAMING_COLORS.items()]\n",
    "ax.legend(handles=legend_elements, loc=\"upper left\", fontsize=9)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"v2_orthogonal_barplot_layer8.png\", dpi=150)\n",
    "print(\"Saved v2_orthogonal_barplot_layer8.png\")\n",
    "plt.close(fig)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}