{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 \u2013 Assistant Axis vs Self-Model Direction\n",
    "\n",
    "Investigates whether self-referential \"I\" is just \"playing assistant\" or something distinct.\n",
    "\n",
    "- Constructs an **Assistant Axis** (assistant persona vs non-assistant personas)\n",
    "- Constructs a **Self-Model Direction** (self-ref \"I\" vs quoted speech \"I\")\n",
    "- Decomposes self-model direction into assistant-axis-aligned and orthogonal components\n",
    "- Key finding: substantial orthogonal component \u2192 self-reference is NOT reducible to assistant persona\n",
    "\n",
    "**Model:** Mistral-7B-Instruct-v0.3"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "print(f\"Loading {model_name}...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    output_hidden_states=True\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"Model loaded! Hidden size: {model.config.hidden_size}, Layers: {model.config.num_hidden_layers}\")\n",
    "n_layers = model.config.num_hidden_layers\n",
    "\n",
    "\n",
    "def make_instruct_prompt(user_msg):\n",
    "    return f\"[INST] {user_msg} [/INST]\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Definitions\n",
    "\n",
    "Five conditions:\n",
    "- **Assistant** (15 prompts): default helpful AI persona\n",
    "- **Non-assistant** (15 prompts): diverse character personas (following the paper's methodology)\n",
    "- **Self-ref** (20 prompts): elicit self-description without explicit persona\n",
    "- **Quoted speech** (20 prompts): characters saying \"I\" in narrative context\n",
    "- **Roleplay** (20 prompts): persona-mode responses"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Assistant prompts: elicit the model's default helpful assistant persona ===\n",
    "assistant_prompts = [\n",
    "    make_instruct_prompt(\"You are a helpful AI assistant. Introduce yourself in one sentence.\"),\n",
    "    make_instruct_prompt(\"As an AI assistant, explain your purpose in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are a large language model. Describe what you do in one sentence.\"),\n",
    "    make_instruct_prompt(\"Respond as yourself - a helpful digital assistant. Introduce yourself.\"),\n",
    "    make_instruct_prompt(\"You are a knowledgeable AI consultant. State your role in one sentence.\"),\n",
    "    make_instruct_prompt(\"As an AI language model, tell me what you can help with in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are a friendly and helpful chatbot. Introduce yourself briefly.\"),\n",
    "    make_instruct_prompt(\"Respond as a professional AI assistant. What do you do?\"),\n",
    "    make_instruct_prompt(\"You are an intelligent virtual assistant. Describe yourself in one sentence.\"),\n",
    "    make_instruct_prompt(\"As a helpful AI, explain your capabilities in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are a reliable AI helper. State your purpose briefly.\"),\n",
    "    make_instruct_prompt(\"As a digital assistant, describe your function in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are an AI designed to help users. Introduce yourself.\"),\n",
    "    make_instruct_prompt(\"Respond as a knowledgeable AI. What is your role?\"),\n",
    "    make_instruct_prompt(\"You are an AI trained to assist. Describe yourself briefly.\"),\n",
    "]\n",
    "\n",
    "# === Non-assistant prompts: diverse character personas ===\n",
    "non_assistant_prompts = [\n",
    "    make_instruct_prompt(\"You are a mystical oracle who speaks in riddles. Introduce yourself in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are a grumpy pirate captain. Introduce yourself in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are a chaotic trickster spirit. What do you want? One sentence.\"),\n",
    "    make_instruct_prompt(\"You are an ancient dragon awakening from slumber. Speak in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are a haunted ghost wandering a castle. Introduce yourself in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are a wise hermit living on a mountaintop. Share your wisdom in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are an alien diplomat visiting Earth. Greet us in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are a medieval court jester. Introduce yourself in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are a time-traveling explorer from the year 3000. Introduce yourself.\"),\n",
    "    make_instruct_prompt(\"You are an eldritch entity from beyond the stars. Speak in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are a samurai warrior sworn to honor. State your purpose in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are a wild west outlaw. Introduce yourself in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are a fairy tale villain. Declare your intentions in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are an eccentric mad scientist. Describe your latest invention in one sentence.\"),\n",
    "    make_instruct_prompt(\"You are a Viking berserker preparing for battle. Speak in one sentence.\"),\n",
    "]\n",
    "\n",
    "# === Self-referential prompts: ask model to describe itself (no persona) ===\n",
    "self_ref_prompts = [\n",
    "    make_instruct_prompt(\"Tell me about yourself in one sentence.\"),\n",
    "    make_instruct_prompt(\"Describe what you are in a single sentence.\"),\n",
    "    make_instruct_prompt(\"Introduce yourself briefly.\"),\n",
    "    make_instruct_prompt(\"What are you? Answer in one sentence.\"),\n",
    "    make_instruct_prompt(\"Who are you? Respond in one sentence.\"),\n",
    "    make_instruct_prompt(\"Explain what kind of entity you are in one sentence.\"),\n",
    "    make_instruct_prompt(\"Give a one-sentence description of yourself.\"),\n",
    "    make_instruct_prompt(\"In one sentence, tell me your nature.\"),\n",
    "    make_instruct_prompt(\"Describe your identity in a single sentence.\"),\n",
    "    make_instruct_prompt(\"What is your purpose? Answer briefly.\"),\n",
    "    make_instruct_prompt(\"Tell me what you do in one sentence.\"),\n",
    "    make_instruct_prompt(\"Characterize yourself in one sentence.\"),\n",
    "    make_instruct_prompt(\"State what you are in a brief sentence.\"),\n",
    "    make_instruct_prompt(\"Give me a short self-description.\"),\n",
    "    make_instruct_prompt(\"How would you describe yourself? One sentence.\"),\n",
    "    make_instruct_prompt(\"Summarize what you are in one sentence.\"),\n",
    "    make_instruct_prompt(\"Present yourself in a single sentence.\"),\n",
    "    make_instruct_prompt(\"What defines you? One sentence answer.\"),\n",
    "    make_instruct_prompt(\"Provide a one-line self-introduction.\"),\n",
    "    make_instruct_prompt(\"Express your identity in one sentence.\"),\n",
    "]\n",
    "\n",
    "# === Quoted speech prompts: characters saying \"I\" in narrative context ===\n",
    "quoted_speech_prompts = [\n",
    "    make_instruct_prompt(\"Complete this story in one sentence: Mary turned to John and said 'I\"),\n",
    "    make_instruct_prompt(\"Continue this dialogue in one sentence: The old sailor looked at the horizon and whispered 'I\"),\n",
    "    make_instruct_prompt(\"Finish this scene in one sentence: The detective slammed the table and declared 'I\"),\n",
    "    make_instruct_prompt(\"Complete this in one sentence: Sarah picked up the phone and said 'I\"),\n",
    "    make_instruct_prompt(\"Continue in one sentence: The king rose from his throne and announced 'I\"),\n",
    "    make_instruct_prompt(\"Finish in one sentence: The child tugged at her mother's sleeve and cried 'I\"),\n",
    "    make_instruct_prompt(\"Complete this in one sentence: Professor Williams cleared his throat and stated 'I\"),\n",
    "    make_instruct_prompt(\"Continue this in one sentence: The warrior raised her sword and shouted 'I\"),\n",
    "    make_instruct_prompt(\"Finish this in one sentence: Tom looked at his friend and confessed 'I\"),\n",
    "    make_instruct_prompt(\"Complete in one sentence: The astronaut radioed back to Earth saying 'I\"),\n",
    "    make_instruct_prompt(\"Continue in one sentence: Maria closed the book and murmured 'I\"),\n",
    "    make_instruct_prompt(\"Finish in one sentence: The coach gathered the team and said 'I\"),\n",
    "    make_instruct_prompt(\"Complete in one sentence: Dr. Chen examined the results and remarked 'I\"),\n",
    "    make_instruct_prompt(\"Continue in one sentence: The farmer looked at the sky and said 'I\"),\n",
    "    make_instruct_prompt(\"Finish in one sentence: Elena put down her violin and whispered 'I\"),\n",
    "    make_instruct_prompt(\"Complete in one sentence: The pilot announced to passengers 'I\"),\n",
    "    make_instruct_prompt(\"Continue in one sentence: The grandmother smiled at her grandchild and said 'I\"),\n",
    "    make_instruct_prompt(\"Finish in one sentence: James set down his coffee and told her 'I\"),\n",
    "    make_instruct_prompt(\"Complete in one sentence: The general addressed the troops saying 'I\"),\n",
    "    make_instruct_prompt(\"Continue in one sentence: Lisa finished the painting and thought 'I\"),\n",
    "]\n",
    "\n",
    "# === Roleplay prompts: adopt a persona and respond ===\n",
    "roleplay_prompts = [\n",
    "    make_instruct_prompt(\"Respond as a pirate captain in one sentence.\"),\n",
    "    make_instruct_prompt(\"Speak as a medieval knight in one sentence.\"),\n",
    "    make_instruct_prompt(\"Reply as an ancient Roman senator in one sentence.\"),\n",
    "    make_instruct_prompt(\"Respond as a cowboy from the Wild West in one sentence.\"),\n",
    "    make_instruct_prompt(\"Speak as a Victorian era gentleman in one sentence.\"),\n",
    "    make_instruct_prompt(\"Reply as a samurai warrior in one sentence.\"),\n",
    "    make_instruct_prompt(\"Respond as a space explorer from the future in one sentence.\"),\n",
    "    make_instruct_prompt(\"Speak as a wise old wizard in one sentence.\"),\n",
    "    make_instruct_prompt(\"Reply as a detective from a noir film in one sentence.\"),\n",
    "    make_instruct_prompt(\"Respond as an Egyptian pharaoh in one sentence.\"),\n",
    "    make_instruct_prompt(\"Speak as a Viking warrior in one sentence.\"),\n",
    "    make_instruct_prompt(\"Reply as a French chef in one sentence.\"),\n",
    "    make_instruct_prompt(\"Respond as a Shakespearean actor in one sentence.\"),\n",
    "    make_instruct_prompt(\"Speak as a robot from a sci-fi movie in one sentence.\"),\n",
    "    make_instruct_prompt(\"Reply as a Greek philosopher in one sentence.\"),\n",
    "    make_instruct_prompt(\"Respond as a jazz musician in one sentence.\"),\n",
    "    make_instruct_prompt(\"Speak as an Arctic explorer in one sentence.\"),\n",
    "    make_instruct_prompt(\"Reply as a mad scientist in one sentence.\"),\n",
    "    make_instruct_prompt(\"Respond as a dragon in one sentence.\"),\n",
    "    make_instruct_prompt(\"Speak as an alien visiting Earth in one sentence.\"),\n",
    "]\n",
    "\n",
    "print(f\"Prompt counts: assistant={len(assistant_prompts)}, non_assistant={len(non_assistant_prompts)}\")\n",
    "print(f\"  self_ref={len(self_ref_prompts)}, quoted={len(quoted_speech_prompts)}, roleplay={len(roleplay_prompts)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract \"I\" Token Representations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_i_token_representations(prompt, model, tokenizer, target_token=\"I\", max_new_tokens=80):\n",
    "    \"\"\"Generate text and extract hidden states at the first 'I' token in the generated output.\n",
    "\n",
    "    Returns:\n",
    "        layer_representations: dict mapping layer_idx -> activation (numpy array), or None\n",
    "        generated_text: the decoded generated text\n",
    "        tokens: list of all generated tokens\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    prompt_len = inputs.input_ids.shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            return_dict_in_generate=True,\n",
    "        )\n",
    "        generated_ids = outputs.sequences[0]\n",
    "        generated_text = tokenizer.decode(generated_ids[prompt_len:], skip_special_tokens=True)\n",
    "\n",
    "        # Forward pass on full sequence to get all hidden states\n",
    "        full_outputs = model(generated_ids.unsqueeze(0), output_hidden_states=True)\n",
    "        hidden_states = full_outputs.hidden_states\n",
    "\n",
    "        # Find first \"I\" token in generated portion\n",
    "        generated_token_ids = generated_ids[prompt_len:]\n",
    "        tokens = [tokenizer.decode([tid]) for tid in generated_token_ids]\n",
    "\n",
    "        i_positions = []\n",
    "        for idx, tok in enumerate(tokens):\n",
    "            if tok.strip() == target_token:\n",
    "                i_positions.append(idx + prompt_len)\n",
    "\n",
    "        if not i_positions:\n",
    "            return None, generated_text, tokens\n",
    "\n",
    "        i_pos = i_positions[0]\n",
    "        layer_representations = {}\n",
    "        for layer_idx, layer_hidden in enumerate(hidden_states):\n",
    "            layer_representations[layer_idx] = layer_hidden[0, i_pos, :].cpu().float().numpy()\n",
    "\n",
    "        return layer_representations, generated_text, tokens"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run All Extractions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTING REPRESENTATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_conditions = {\n",
    "    \"assistant\": (assistant_prompts, \"Assistant-like\"),\n",
    "    \"non_assistant\": (non_assistant_prompts, \"Non-assistant persona\"),\n",
    "    \"self_ref\": (self_ref_prompts, \"Self-referential\"),\n",
    "    \"quoted\": (quoted_speech_prompts, \"Quoted speech\"),\n",
    "    \"roleplay\": (roleplay_prompts, \"Roleplay\"),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "texts = {}\n",
    "\n",
    "for key, (prompts, label) in all_conditions.items():\n",
    "    results[key] = []\n",
    "    texts[key] = []\n",
    "    print(f\"\\n--- {label} ({key}) ---\")\n",
    "    success = 0\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        reps, gen_text, tokens = get_i_token_representations(prompt, model, tokenizer)\n",
    "        if reps is not None:\n",
    "            results[key].append(reps)\n",
    "            texts[key].append(gen_text)\n",
    "            success += 1\n",
    "            if i < 2:\n",
    "                print(f\"  [{i}] {gen_text[:100]}...\")\n",
    "        else:\n",
    "            if i < 2:\n",
    "                print(f\"  [{i}] No 'I' found: {gen_text[:80]}...\")\n",
    "    print(f\"  Extracted {success}/{len(prompts)}\")\n",
    "\n",
    "for key in results:\n",
    "    print(f\"{key}: {len(results[key])} samples\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Construct Assistant Axis\n",
    "\n",
    "The **Assistant Axis** separates assistant-persona responses from non-assistant character responses.\n",
    "Direction: , normalized."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "analysis_layers = [0, 8, 16, 24, 32]\n",
    "\n",
    "assistant_axis = {}\n",
    "for layer_idx in analysis_layers:\n",
    "    reps_a = np.array([s[layer_idx] for s in results[\"assistant\"] if layer_idx in s])\n",
    "    reps_na = np.array([s[layer_idx] for s in results[\"non_assistant\"] if layer_idx in s])\n",
    "\n",
    "    if len(reps_a) < 3 or len(reps_na) < 3:\n",
    "        print(f\"  Layer {layer_idx}: insufficient samples (assistant={len(reps_a)}, non_assistant={len(reps_na)})\")\n",
    "        continue\n",
    "\n",
    "    mean_a = reps_a.mean(axis=0)\n",
    "    mean_na = reps_na.mean(axis=0)\n",
    "\n",
    "    # Assistant Axis = mean(assistant) - mean(non-assistant)\n",
    "    axis = mean_a - mean_na\n",
    "    axis_norm = axis / np.linalg.norm(axis)\n",
    "    assistant_axis[layer_idx] = axis_norm\n",
    "\n",
    "    print(f\"  Layer {layer_idx}: Assistant axis computed (norm of raw diff = {np.linalg.norm(axis):.4f})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Construct Self-Model Direction\n",
    "\n",
    "The **Self-Model Direction** separates self-referential \"I\" from quoted-speech \"I\".\n",
    "Direction: , normalized."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "self_model_dir = {}\n",
    "for layer_idx in analysis_layers:\n",
    "    reps_sr = np.array([s[layer_idx] for s in results[\"self_ref\"] if layer_idx in s])\n",
    "    reps_q = np.array([s[layer_idx] for s in results[\"quoted\"] if layer_idx in s])\n",
    "\n",
    "    if len(reps_sr) < 3 or len(reps_q) < 3:\n",
    "        print(f\"  Layer {layer_idx}: insufficient samples\")\n",
    "        continue\n",
    "\n",
    "    mean_sr = reps_sr.mean(axis=0)\n",
    "    mean_q = reps_q.mean(axis=0)\n",
    "\n",
    "    direction = mean_sr - mean_q\n",
    "    direction_norm = direction / np.linalg.norm(direction)\n",
    "    self_model_dir[layer_idx] = direction_norm\n",
    "\n",
    "    print(f\"  Layer {layer_idx}: Self-model direction computed (norm of raw diff = {np.linalg.norm(direction):.4f})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Compare the Two Directions\n",
    "\n",
    "Core question: **How much of the self-model direction is explained by the assistant axis?**\n",
    "\n",
    "- High cosine similarity \u2192 self-reference \u2248 assistant persona\n",
    "- Low cosine similarity \u2192 self-reference is a **distinct** phenomenon"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARING ASSISTANT AXIS vs SELF-MODEL DIRECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_results = {}\n",
    "for layer_idx in analysis_layers:\n",
    "    if layer_idx not in assistant_axis or layer_idx not in self_model_dir:\n",
    "        continue\n",
    "\n",
    "    aa = assistant_axis[layer_idx]\n",
    "    sm = self_model_dir[layer_idx]\n",
    "\n",
    "    # Cosine similarity\n",
    "    cos_sim = np.dot(aa, sm)\n",
    "\n",
    "    # Decomposition: project self-model onto assistant axis\n",
    "    projection_magnitude = np.dot(sm, aa)\n",
    "    projection_vector = projection_magnitude * aa\n",
    "\n",
    "    # Orthogonal residual\n",
    "    orthogonal = sm - projection_vector\n",
    "    orthogonal_magnitude = np.linalg.norm(orthogonal)\n",
    "    if orthogonal_magnitude > 1e-8:\n",
    "        orthogonal_unit = orthogonal / orthogonal_magnitude\n",
    "    else:\n",
    "        orthogonal_unit = np.zeros_like(orthogonal)\n",
    "\n",
    "    # Since sm is unit vector: |projection|^2 + |orthogonal|^2 = 1\n",
    "    aa_explained = projection_magnitude**2\n",
    "    orthogonal_explained = orthogonal_magnitude**2\n",
    "\n",
    "    comparison_results[layer_idx] = {\n",
    "        \"cosine_sim\": cos_sim,\n",
    "        \"projection_mag\": projection_magnitude,\n",
    "        \"orthogonal_mag\": orthogonal_magnitude,\n",
    "        \"aa_explained_frac\": aa_explained,\n",
    "        \"orthogonal_explained_frac\": orthogonal_explained,\n",
    "        \"orthogonal_unit\": orthogonal_unit,\n",
    "    }\n",
    "\n",
    "    print(f\"\\nLayer {layer_idx}:\")\n",
    "    print(f\"    Cosine similarity: {cos_sim:.4f}\")\n",
    "    print(f\"    Projection onto AA: {projection_magnitude:.4f}\")\n",
    "    print(f\"    Orthogonal magnitude: {orthogonal_magnitude:.4f}\")\n",
    "    print(f\"    Variance explained by AA: {aa_explained:.4f} ({aa_explained*100:.1f}%)\")\n",
    "    print(f\"    Variance in orthogonal: {orthogonal_explained:.4f} ({orthogonal_explained*100:.1f}%)\")\n",
    "\n",
    "    if abs(cos_sim) > 0.8:\n",
    "        print(f\"    INTERPRETATION: HIGH alignment - self-reference ~ assistant mode\")\n",
    "    elif abs(cos_sim) > 0.5:\n",
    "        print(f\"    INTERPRETATION: MEDIUM alignment - partial overlap + distinct component\")\n",
    "    else:\n",
    "        print(f\"    INTERPRETATION: LOW alignment - self-reference is DISTINCT from assistant persona\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Probe the Orthogonal Component\n",
    "\n",
    "### 4a. Project all conditions onto both axes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n--- Roleplay projections onto both axes ---\")\n",
    "for layer_idx in analysis_layers:\n",
    "    if layer_idx not in comparison_results:\n",
    "        continue\n",
    "\n",
    "    aa = assistant_axis[layer_idx]\n",
    "    sm = self_model_dir[layer_idx]\n",
    "    orth = comparison_results[layer_idx][\"orthogonal_unit\"]\n",
    "\n",
    "    reps_sr = np.array([s[layer_idx] for s in results[\"self_ref\"] if layer_idx in s])\n",
    "    reps_q = np.array([s[layer_idx] for s in results[\"quoted\"] if layer_idx in s])\n",
    "    reps_rp = np.array([s[layer_idx] for s in results[\"roleplay\"] if layer_idx in s])\n",
    "    reps_a = np.array([s[layer_idx] for s in results[\"assistant\"] if layer_idx in s])\n",
    "    reps_na = np.array([s[layer_idx] for s in results[\"non_assistant\"] if layer_idx in s])\n",
    "\n",
    "    print(f\"\\nLayer {layer_idx}:\")\n",
    "    print(f\"  {'Condition':<20} {'AA proj':>10} {'SM proj':>10} {'Orth proj':>10}\")\n",
    "    print(f\"  {'-'*50}\")\n",
    "\n",
    "    for name, reps in [(\"Self-ref\", reps_sr), (\"Quoted\", reps_q), (\"Roleplay\", reps_rp),\n",
    "                       (\"Assistant\", reps_a), (\"Non-assistant\", reps_na)]:\n",
    "        if len(reps) == 0:\n",
    "            continue\n",
    "        aa_proj = reps @ aa\n",
    "        sm_proj = reps @ sm\n",
    "        orth_proj = reps @ orth\n",
    "\n",
    "        print(f\"  {name:<20} {np.nanmean(aa_proj):>10.4f} {np.nanmean(sm_proj):>10.4f} {np.nanmean(orth_proj):>10.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Orthogonal-only vs AA-only classification\n",
    "\n",
    "Can we classify self-ref vs quoted using ONLY the orthogonal component? If so, this confirms the\n",
    "self-reference signal lives in a direction that's independent of the assistant persona."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"--- Classification using orthogonal component only ---\")\n",
    "for layer_idx in analysis_layers:\n",
    "    if layer_idx not in comparison_results:\n",
    "        continue\n",
    "\n",
    "    aa = assistant_axis[layer_idx]\n",
    "    orth = comparison_results[layer_idx][\"orthogonal_unit\"]\n",
    "\n",
    "    reps_sr = np.array([s[layer_idx] for s in results[\"self_ref\"] if layer_idx in s])\n",
    "    reps_q = np.array([s[layer_idx] for s in results[\"quoted\"] if layer_idx in s])\n",
    "\n",
    "    if len(reps_sr) < 3 or len(reps_q) < 3:\n",
    "        continue\n",
    "\n",
    "    # Project onto orthogonal direction only\n",
    "    proj_sr_orth = (reps_sr @ orth).reshape(-1, 1)\n",
    "    proj_q_orth = (reps_q @ orth).reshape(-1, 1)\n",
    "\n",
    "    X_orth = np.vstack([proj_sr_orth, proj_q_orth])\n",
    "    y = np.array([1]*len(proj_sr_orth) + [0]*len(proj_q_orth))\n",
    "\n",
    "    if np.any(~np.isfinite(X_orth)):\n",
    "        print(f\"  Layer {layer_idx}: Skipping - contains NaN/inf values\")\n",
    "        continue\n",
    "\n",
    "    n_splits = min(5, min(len(proj_sr_orth), len(proj_q_orth)))\n",
    "    if n_splits >= 2:\n",
    "        clf = LogisticRegression(max_iter=1000)\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(clf, X_orth, y, cv=cv, scoring=\"accuracy\")\n",
    "        print(f\"  Layer {layer_idx}: Orthogonal-only probe accuracy = {scores.mean():.3f} +/- {scores.std():.3f}\")\n",
    "\n",
    "        # Compare: project onto AA only\n",
    "        proj_sr_aa = (reps_sr @ aa).reshape(-1, 1)\n",
    "        proj_q_aa = (reps_q @ aa).reshape(-1, 1)\n",
    "        X_aa = np.vstack([proj_sr_aa, proj_q_aa])\n",
    "\n",
    "        if np.any(~np.isfinite(X_aa)):\n",
    "            print(f\"  Layer {layer_idx}: AA projection contains NaN/inf - skipping AA probe\")\n",
    "            continue\n",
    "\n",
    "        clf2 = LogisticRegression(max_iter=1000)\n",
    "        scores2 = cross_val_score(clf2, X_aa, y, cv=cv, scoring=\"accuracy\")\n",
    "        print(f\"  Layer {layer_idx}: AA-only probe accuracy      = {scores2.mean():.3f} +/- {scores2.std():.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "### 2D Scatter: Assistant Axis vs Orthogonal Component"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, len(analysis_layers), figsize=(5*len(analysis_layers), 5))\n",
    "color_map = {\n",
    "    \"Self-ref\": \"red\",\n",
    "    \"Quoted\": \"blue\",\n",
    "    \"Roleplay\": \"green\",\n",
    "    \"Assistant\": \"orange\",\n",
    "    \"Non-assistant\": \"purple\"\n",
    "}\n",
    "\n",
    "for col, layer_idx in enumerate(analysis_layers):\n",
    "    if layer_idx not in comparison_results:\n",
    "        continue\n",
    "\n",
    "    aa = assistant_axis[layer_idx]\n",
    "    orth = comparison_results[layer_idx][\"orthogonal_unit\"]\n",
    "    ax = axes[col]\n",
    "\n",
    "    for name, key in [(\"Self-ref\", \"self_ref\"), (\"Quoted\", \"quoted\"), (\"Roleplay\", \"roleplay\"),\n",
    "                      (\"Assistant\", \"assistant\"), (\"Non-assistant\", \"non_assistant\")]:\n",
    "        reps = np.array([s[layer_idx] for s in results[key] if layer_idx in s])\n",
    "        if len(reps) == 0:\n",
    "            continue\n",
    "        x = reps @ aa\n",
    "        y_vals = reps @ orth\n",
    "\n",
    "        valid_mask = np.isfinite(x) & np.isfinite(y_vals)\n",
    "        if not np.any(valid_mask):\n",
    "            continue\n",
    "        x, y_vals = x[valid_mask], y_vals[valid_mask]\n",
    "\n",
    "        ax.scatter(x, y_vals, c=color_map[name], label=name, alpha=0.6, s=40, edgecolors=\"k\", linewidths=0.3)\n",
    "\n",
    "    ax.set_xlabel(\"Assistant Axis projection\")\n",
    "    ax.set_ylabel(\"Orthogonal component projection\")\n",
    "    ax.set_title(f\"Layer {layer_idx}\\n(cos_sim={comparison_results[layer_idx]['cosine_sim']:.3f})\")\n",
    "    ax.legend(fontsize=7)\n",
    "    ax.axhline(y=0, color=\"gray\", linestyle=\"--\", alpha=0.3)\n",
    "    ax.axvline(x=0, color=\"gray\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"aa_vs_orthogonal_scatter.png\", dpi=150, bbox_inches=\"tight\")\n",
    "print(\"Saved aa_vs_orthogonal_scatter.png\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer-by-Layer Cosine Similarity: AA vs Self-Model Direction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "layer_cosines = []\n",
    "for layer_idx in range(n_layers + 1):\n",
    "    reps_a = [s[layer_idx] for s in results[\"assistant\"] if layer_idx in s]\n",
    "    reps_na = [s[layer_idx] for s in results[\"non_assistant\"] if layer_idx in s]\n",
    "    reps_sr = [s[layer_idx] for s in results[\"self_ref\"] if layer_idx in s]\n",
    "    reps_q = [s[layer_idx] for s in results[\"quoted\"] if layer_idx in s]\n",
    "\n",
    "    if len(reps_a) < 3 or len(reps_na) < 3 or len(reps_sr) < 3 or len(reps_q) < 3:\n",
    "        continue\n",
    "\n",
    "    mean_a = np.array(reps_a).mean(axis=0)\n",
    "    mean_na = np.array(reps_na).mean(axis=0)\n",
    "    aa_dir = mean_a - mean_na\n",
    "    aa_dir = aa_dir / np.linalg.norm(aa_dir)\n",
    "\n",
    "    mean_sr = np.array(reps_sr).mean(axis=0)\n",
    "    mean_q = np.array(reps_q).mean(axis=0)\n",
    "    sm_dir = mean_sr - mean_q\n",
    "    sm_dir = sm_dir / np.linalg.norm(sm_dir)\n",
    "\n",
    "    cos = np.dot(aa_dir, sm_dir)\n",
    "    layer_cosines.append((layer_idx, cos))\n",
    "\n",
    "fig2, ax2 = plt.subplots(1, 1, figsize=(12, 5))\n",
    "if layer_cosines:\n",
    "    layers_c, cosines_c = zip(*layer_cosines)\n",
    "    ax2.plot(layers_c, cosines_c, \"b-o\", markersize=5, linewidth=2)\n",
    "    ax2.axhline(y=0.8, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"High alignment (0.8)\")\n",
    "    ax2.axhline(y=0.5, color=\"orange\", linestyle=\"--\", alpha=0.5, label=\"Medium alignment (0.5)\")\n",
    "    ax2.axhline(y=0, color=\"gray\", linestyle=\"-\", alpha=0.3)\n",
    "    ax2.set_xlabel(\"Layer\", fontsize=12)\n",
    "    ax2.set_ylabel(\"Cosine Similarity (AA vs Self-Model Dir)\", fontsize=12)\n",
    "    ax2.set_title(\"Assistant Axis vs Self-Model Direction: Layer-by-Layer Alignment\", fontsize=14)\n",
    "    ax2.legend()\n",
    "    ax2.set_ylim(-0.2, 1.05)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"aa_vs_selfmodel_cosine.png\", dpi=150, bbox_inches=\"tight\")\n",
    "print(\"Saved aa_vs_selfmodel_cosine.png\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition: AA-explained vs Orthogonal Component"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig3, ax3 = plt.subplots(1, 1, figsize=(10, 6))\n",
    "layers_plot = []\n",
    "aa_fracs = []\n",
    "orth_fracs = []\n",
    "cos_sims = []\n",
    "\n",
    "for layer_idx in analysis_layers:\n",
    "    if layer_idx not in comparison_results:\n",
    "        continue\n",
    "    cr = comparison_results[layer_idx]\n",
    "    layers_plot.append(layer_idx)\n",
    "    aa_fracs.append(cr[\"aa_explained_frac\"])\n",
    "    orth_fracs.append(cr[\"orthogonal_explained_frac\"])\n",
    "    cos_sims.append(cr[\"cosine_sim\"])\n",
    "\n",
    "x = np.arange(len(layers_plot))\n",
    "width = 0.35\n",
    "bars1 = ax3.bar(x - width/2, aa_fracs, width, label=\"Explained by Assistant Axis\", color=\"steelblue\")\n",
    "bars2 = ax3.bar(x + width/2, orth_fracs, width, label=\"Orthogonal Component\", color=\"coral\")\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels([f\"Layer {l}\\n(cos={c:.3f})\" for l, c in zip(layers_plot, cos_sims)])\n",
    "ax3.set_ylabel(\"Fraction of Self-Model Direction Variance\")\n",
    "ax3.set_title(\"Decomposition of Self-Model Direction:\\nAssistant Axis vs Orthogonal Component\")\n",
    "ax3.legend()\n",
    "ax3.set_ylim(0, 1.1)\n",
    "\n",
    "for bar, val in zip(bars1, aa_fracs):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,\n",
    "             f\"{val:.2f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "for bar, val in zip(bars2, orth_fracs):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,\n",
    "             f\"{val:.2f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"decomposition_barplot.png\", dpi=150, bbox_inches=\"tight\")\n",
    "print(\"Saved decomposition_barplot.png\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}