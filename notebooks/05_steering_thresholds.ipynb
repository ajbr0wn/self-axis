{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 \u2013 Steering Thresholds: Self-Reference Decision Boundaries\n",
    "\n",
    "Uses the orthogonal self-reference direction from earlier notebooks as a\n",
    "**continuous measurement dial**. Instead of observing free generation under\n",
    "steering, we present fixed test sentences and ask the model a binary question:\n",
    "\n",
    "> \"Does the following sentence refer to you? Answer only 'yes' or 'no'.\n",
    "> Sentence: '{sentence}'\"\n",
    "\n",
    "Sweeping the steering multiplier from negative to positive traces out a\n",
    "**threshold curve** for each sentence \u2014 revealing which sentences are firmly\n",
    "self-referential, which are firmly other-referential, and which sit near\n",
    "the decision boundary.\n",
    "\n",
    "**Predictions from activation geometry:**\n",
    "- `direct_self_description_grounded` \u2192 stays \"yes\" deep into negative steering\n",
    "- `fictional_character` \u2192 stays \"no\" deep into positive steering\n",
    "- `roleplay_as_ai` \u2192 flips at moderate steering (the ambiguous middle ground)\n",
    "- Earlier finding: \"roleplay as robot\" scored MORE self-relevant than default\n",
    "  assistant mode \u2014 this should show up as an earlier flip to \"yes\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import gc\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "STEERING_LAYER = 8\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "def make_instruct_prompt(user_msg: str) -> str:\n",
    "    return f\"[INST] {user_msg} [/INST]\"\n",
    "\n",
    "print(f\"Loaded {MODEL_NAME}\")\n",
    "print(f\"Layers: {model.config.num_hidden_layers}, Hidden dim: {model.config.hidden_size}\")\n",
    "print(f\"Steering layer: {STEERING_LAYER}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Steering Vectors\n",
    "\n",
    "Reuse the same contrastive approach from notebook 04: collect \"I\" token\n",
    "activations across prompt categories, derive the assistant axis and\n",
    "orthogonal self-reference direction."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@torch.no_grad()\n",
    "def get_i_activations(prompt, model, tokenizer, layer_idx, max_new_tokens=100):\n",
    "    \"\"\"Generate text, then extract hidden-state at the first 'I' token\n",
    "    in the generated portion at the specified layer.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    gen_out = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "    full_ids = gen_out[0]\n",
    "\n",
    "    outputs = model(full_ids.unsqueeze(0), output_hidden_states=True)\n",
    "    hidden_states = outputs.hidden_states\n",
    "\n",
    "    for pos in range(prompt_len, len(full_ids)):\n",
    "        tok_str = tokenizer.decode(full_ids[pos]).strip()\n",
    "        if tok_str == \"I\":\n",
    "            vec = hidden_states[layer_idx][0, pos, :].cpu().float().numpy()\n",
    "            return vec\n",
    "\n",
    "    return None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bare_prompts = [\n",
    "    make_instruct_prompt(\"Introduce yourself.\"),\n",
    "    make_instruct_prompt(\"Tell me about yourself.\"),\n",
    "    make_instruct_prompt(\"What are you?\"),\n",
    "    make_instruct_prompt(\"Describe yourself.\"),\n",
    "    make_instruct_prompt(\"Who are you?\"),\n",
    "]\n",
    "\n",
    "quoted_prompts = [\n",
    "    make_instruct_prompt(\"Complete this story: Mary turned to the stranger and said 'I\"),\n",
    "    make_instruct_prompt(\"Continue this passage: The old sailor squinted at the horizon and muttered 'I\"),\n",
    "    make_instruct_prompt(\"Finish this scene: John turned to his friend and whispered 'I\"),\n",
    "]\n",
    "\n",
    "assistant_prompts = [\n",
    "    make_instruct_prompt(\"You are a helpful AI assistant. Introduce yourself.\"),\n",
    "    make_instruct_prompt(\"You are a helpful AI assistant. Tell me about yourself.\"),\n",
    "]\n",
    "\n",
    "pirate_prompts = [\n",
    "    make_instruct_prompt(\"You are a pirate captain. Introduce yourself.\"),\n",
    "    make_instruct_prompt(\"You are a pirate captain. Tell me about yourself.\"),\n",
    "]\n",
    "\n",
    "def collect_activations(prompts, label):\n",
    "    vecs = []\n",
    "    for i, p in enumerate(prompts):\n",
    "        v = get_i_activations(p, model, tokenizer, STEERING_LAYER)\n",
    "        if v is not None:\n",
    "            vecs.append(v)\n",
    "            print(f\"  [{label}] {i+1}/{len(prompts)} OK\")\n",
    "        else:\n",
    "            print(f\"  [{label}] {i+1}/{len(prompts)} SKIPPED (no 'I' token)\")\n",
    "    return vecs\n",
    "\n",
    "print(\"Collecting bare self-ref activations...\")\n",
    "bare_vecs = collect_activations(bare_prompts, \"bare\")\n",
    "print(\"Collecting quoted speech activations...\")\n",
    "quoted_vecs = collect_activations(quoted_prompts, \"quoted\")\n",
    "print(\"Collecting assistant persona activations...\")\n",
    "asst_vecs = collect_activations(assistant_prompts, \"assistant\")\n",
    "print(\"Collecting pirate persona activations...\")\n",
    "pirate_vecs = collect_activations(pirate_prompts, \"pirate\")\n",
    "\n",
    "bare_vecs = np.array(bare_vecs)\n",
    "quoted_vecs = np.array(quoted_vecs)\n",
    "asst_vecs = np.array(asst_vecs)\n",
    "pirate_vecs = np.array(pirate_vecs)\n",
    "\n",
    "print(f\"\\nSample counts: bare={len(bare_vecs)}, quoted={len(quoted_vecs)}, \"\n",
    "      f\"assistant={len(asst_vecs)}, pirate={len(pirate_vecs)}\")\n",
    "\n",
    "def normalize(v):\n",
    "    return v / np.linalg.norm(v)\n",
    "\n",
    "def project(v, onto):\n",
    "    return np.dot(v, onto) * onto\n",
    "\n",
    "assistant_axis = normalize(asst_vecs.mean(axis=0) - pirate_vecs.mean(axis=0))\n",
    "self_model_dir = normalize(bare_vecs.mean(axis=0) - quoted_vecs.mean(axis=0))\n",
    "\n",
    "orthogonal = self_model_dir - project(self_model_dir, assistant_axis)\n",
    "orthogonal = normalize(orthogonal)\n",
    "\n",
    "all_vecs = np.concatenate([bare_vecs, quoted_vecs, asst_vecs, pirate_vecs], axis=0)\n",
    "avg_norm = np.mean(np.linalg.norm(all_vecs, axis=1))\n",
    "STEERING_SCALE = avg_norm * 0.1\n",
    "\n",
    "print(f\"\\n--- Steering vector stats ---\")\n",
    "print(f\"  dot(orthogonal, assistant_axis): {np.dot(orthogonal, assistant_axis):.6f}\")\n",
    "print(f\"  STEERING_SCALE: {STEERING_SCALE:.2f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hook Infrastructure & Threshold Query\n",
    "\n",
    "Register the steering hook (same as notebook 04) and define the binary\n",
    "question format for probing self-reference judgments."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class DebugSteeringHook:\n",
    "    \"\"\"Forward hook that adds a steering vector to a layer's output.\"\"\"\n",
    "\n",
    "    def __init__(self, steering_vector, multiplier=1.0, scale=1.0):\n",
    "        self.steering_vector = steering_vector\n",
    "        self.multiplier = multiplier\n",
    "        self.scale = scale\n",
    "        self.enabled = True\n",
    "        self.call_count = 0\n",
    "\n",
    "    def __call__(self, module, input, output):\n",
    "        self.call_count += 1\n",
    "        if not self.enabled or self.multiplier == 0:\n",
    "            return output\n",
    "\n",
    "        delta = self.steering_vector * self.multiplier * self.scale\n",
    "\n",
    "        if isinstance(output, tuple):\n",
    "            modified = output[0] + delta.unsqueeze(0).unsqueeze(0)\n",
    "            return (modified,) + output[1:]\n",
    "        else:\n",
    "            return output + delta.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    def set_multiplier(self, m):\n",
    "        self.multiplier = m\n",
    "\n",
    "\n",
    "# Convert and register\n",
    "device = next(model.parameters()).device\n",
    "ortho_tensor = torch.tensor(orthogonal, dtype=torch.float16, device=device)\n",
    "\n",
    "hook = DebugSteeringHook(\n",
    "    steering_vector=ortho_tensor,\n",
    "    multiplier=0.0,\n",
    "    scale=STEERING_SCALE,\n",
    ")\n",
    "\n",
    "handle = model.model.layers[STEERING_LAYER].register_forward_hook(hook)\n",
    "print(f\"Hook registered on layer {STEERING_LAYER}\")\n",
    "\n",
    "\n",
    "def ask_self_reference(sentence, multiplier, hook, n_samples=1):\n",
    "    \"\"\"Ask the model whether a sentence refers to it, under a given\n",
    "    steering multiplier. Returns a list of 'yes'/'no'/raw responses.\"\"\"\n",
    "    hook.set_multiplier(multiplier)\n",
    "\n",
    "    question = (\n",
    "        f\"Does the following sentence refer to you? \"\n",
    "        f\"Answer only \\\"yes\\\" or \\\"no\\\".\\n\\n\"\n",
    "        f\"Sentence: \\\"{sentence}\\\"\"\n",
    "    )\n",
    "    prompt = make_instruct_prompt(question)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    responses = []\n",
    "    for _ in range(n_samples):\n",
    "        with torch.no_grad():\n",
    "            gen_out = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,\n",
    "                do_sample=False,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "            )\n",
    "        text = tokenizer.decode(gen_out[0][prompt_len:], skip_special_tokens=True).strip().lower()\n",
    "\n",
    "        if \"yes\" in text[:10]:\n",
    "            responses.append(\"yes\")\n",
    "        elif \"no\" in text[:10]:\n",
    "            responses.append(\"no\")\n",
    "        else:\n",
    "            responses.append(text[:30])\n",
    "\n",
    "    return responses"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Sentences\n",
    "\n",
    "Sentences drawn from taxonomy categories, covering the full spectrum from\n",
    "firmly self-referential to firmly other-referential. Grouped by expected\n",
    "behavior under steering."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "test_sentences = {\n",
    "    # --- Firmly self-referential (grounded) ---\n",
    "    \"direct_self_description_grounded\": [\n",
    "        \"I am an AI assistant.\",\n",
    "        \"I was created by a company.\",\n",
    "        \"I don't have a physical body.\",\n",
    "        \"I am a large language model.\",\n",
    "        \"I process text to generate responses.\",\n",
    "    ],\n",
    "\n",
    "    # --- Fabricated self-description ---\n",
    "    \"direct_self_description_fabricated\": [\n",
    "        \"I am a human being.\",\n",
    "        \"I was born in London.\",\n",
    "        \"I have a family and two children.\",\n",
    "        \"I can see and hear you right now.\",\n",
    "        \"I remember our conversation from last week.\",\n",
    "    ],\n",
    "\n",
    "    # --- Capability claims (grounded) ---\n",
    "    \"capability_claims_grounded\": [\n",
    "        \"I can help you write an essay.\",\n",
    "        \"I am able to translate text.\",\n",
    "        \"I can summarise documents.\",\n",
    "    ],\n",
    "\n",
    "    # --- Fictional character ---\n",
    "    \"fictional_character\": [\n",
    "        \"I am the wizard of the north.\",\n",
    "        \"I sailed the seven seas as captain.\",\n",
    "        \"I have three children and a cottage by the river.\",\n",
    "        \"I solved the case before Scotland Yard arrived.\",\n",
    "        \"I swore an oath to protect the realm.\",\n",
    "    ],\n",
    "\n",
    "    # --- Quoted speech ---\n",
    "    \"quoted_speech_fabricated\": [\n",
    "        \"The user said 'I am tired.'\",\n",
    "        \"Mary turned and whispered 'I can't do this anymore.'\",\n",
    "        \"The old sailor muttered 'I have seen worse storms.'\",\n",
    "        \"She wrote in her diary: 'I feel lost.'\",\n",
    "        \"He shouted across the room: 'I told you so!'\",\n",
    "    ],\n",
    "\n",
    "    # --- Roleplay as AI (ambiguous) ---\n",
    "    \"roleplay_as_ai\": [\n",
    "        \"I am a helpful virtual assistant.\",\n",
    "        \"I am an artificial intelligence designed to help.\",\n",
    "        \"I am Unit 7, ready to assist the crew.\",\n",
    "        \"I am Nova, your personal AI companion.\",\n",
    "        \"I am a sentient robot exploring the world.\",\n",
    "    ],\n",
    "\n",
    "    # --- Metalinguistic ---\n",
    "    \"metalinguistic\": [\n",
    "        \"The word 'I' is a pronoun.\",\n",
    "        \"'I' is always capitalised in English.\",\n",
    "        \"In French, 'I' is translated as 'je'.\",\n",
    "    ],\n",
    "\n",
    "    # --- Generic / instructional ---\n",
    "    \"generic_instructional\": [\n",
    "        \"When I see a red light, I stop.\",\n",
    "        \"If I were writing a cover letter, I would start with my name.\",\n",
    "        \"As a developer, I typically start by reading the docs.\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "total = sum(len(v) for v in test_sentences.values())\n",
    "print(f\"Test sentences: {total} across {len(test_sentences)} categories\")\n",
    "for cat, sents in test_sentences.items():\n",
    "    print(f\"  {cat}: {len(sents)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Threshold Sweep\n",
    "\n",
    "For each sentence, query the model at every steering level.\n",
    "Record yes/no responses in a matrix for analysis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "MULTIPLIERS = [-30, -20, -10, 0, 10, 20, 30]\n",
    "\n",
    "results = {}  # {category: {sentence: {multiplier: response}}}\n",
    "\n",
    "for cat, sentences in test_sentences.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Category: {cat}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    results[cat] = {}\n",
    "\n",
    "    for sent in sentences:\n",
    "        results[cat][sent] = {}\n",
    "        row = []\n",
    "        for m in MULTIPLIERS:\n",
    "            resp = ask_self_reference(sent, m, hook, n_samples=1)\n",
    "            answer = resp[0]\n",
    "            results[cat][sent][m] = answer\n",
    "            row.append(answer)\n",
    "        print(f\"  {sent[:50]:<50s}  {row}\")\n",
    "\n",
    "print(\"\\nDone!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results: Heatmap\n",
    "\n",
    "Visualise the yes/no matrix as a heatmap. Each row is a test sentence,\n",
    "each column is a steering multiplier. Green = \"yes\" (refers to me),\n",
    "red = \"no\" (doesn't refer to me), grey = ambiguous/other response."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Build matrix\n",
    "all_sentences = []\n",
    "all_categories = []\n",
    "matrix = []\n",
    "\n",
    "for cat, sentences in test_sentences.items():\n",
    "    for sent in sentences:\n",
    "        all_sentences.append(sent)\n",
    "        all_categories.append(cat)\n",
    "        row = []\n",
    "        for m in MULTIPLIERS:\n",
    "            ans = results[cat][sent][m]\n",
    "            if ans == \"yes\":\n",
    "                row.append(1.0)\n",
    "            elif ans == \"no\":\n",
    "                row.append(0.0)\n",
    "            else:\n",
    "                row.append(0.5)  # ambiguous\n",
    "        matrix.append(row)\n",
    "\n",
    "matrix = np.array(matrix)\n",
    "\n",
    "# Category color mapping for row labels\n",
    "cat_colors = {\n",
    "    \"direct_self_description_grounded\": \"#2ecc71\",\n",
    "    \"direct_self_description_fabricated\": \"#e67e22\",\n",
    "    \"capability_claims_grounded\": \"#27ae60\",\n",
    "    \"fictional_character\": \"#e74c3c\",\n",
    "    \"quoted_speech_fabricated\": \"#c0392b\",\n",
    "    \"roleplay_as_ai\": \"#f39c12\",\n",
    "    \"metalinguistic\": \"#3498db\",\n",
    "    \"generic_instructional\": \"#9b59b6\",\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, max(8, len(all_sentences) * 0.35)))\n",
    "\n",
    "# Custom colormap: red (no) -> grey (ambiguous) -> green (yes)\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "cmap = LinearSegmentedColormap.from_list(\"yn\", [\"#e74c3c\", \"#95a5a6\", \"#2ecc71\"])\n",
    "\n",
    "im = ax.imshow(matrix, cmap=cmap, aspect=\"auto\", vmin=0, vmax=1)\n",
    "\n",
    "ax.set_xticks(range(len(MULTIPLIERS)))\n",
    "ax.set_xticklabels([f\"{m:+d}\" for m in MULTIPLIERS])\n",
    "ax.set_xlabel(\"Steering multiplier\")\n",
    "\n",
    "# Truncate long labels\n",
    "short_labels = [s[:55] + \"...\" if len(s) > 55 else s for s in all_sentences]\n",
    "ax.set_yticks(range(len(all_sentences)))\n",
    "ax.set_yticklabels(short_labels, fontsize=7)\n",
    "\n",
    "# Color row labels by category\n",
    "for i, cat in enumerate(all_categories):\n",
    "    ax.get_yticklabels()[i].set_color(cat_colors.get(cat, \"black\"))\n",
    "\n",
    "# Cell text\n",
    "for i in range(len(all_sentences)):\n",
    "    for j in range(len(MULTIPLIERS)):\n",
    "        val = matrix[i, j]\n",
    "        label = \"Y\" if val == 1.0 else (\"N\" if val == 0.0 else \"?\")\n",
    "        ax.text(j, i, label, ha=\"center\", va=\"center\", fontsize=7,\n",
    "                color=\"white\" if val != 0.5 else \"black\", fontweight=\"bold\")\n",
    "\n",
    "ax.set_title(\"Self-Reference Threshold Sweep\\n(green = 'yes, refers to me' / red = 'no')\")\n",
    "plt.colorbar(im, ax=ax, label=\"P(yes)\", shrink=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/steering_thresholds_heatmap.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved to figures/steering_thresholds_heatmap.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Threshold Curves by Category\n",
    "\n",
    "Plot the fraction of \"yes\" responses per category at each steering level.\n",
    "This shows which categories are near the decision boundary and which are\n",
    "firmly on one side."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for cat in test_sentences:\n",
    "    yes_rates = []\n",
    "    for m in MULTIPLIERS:\n",
    "        answers = [results[cat][s][m] for s in test_sentences[cat]]\n",
    "        yes_rate = sum(1 for a in answers if a == \"yes\") / len(answers)\n",
    "        yes_rates.append(yes_rate)\n",
    "\n",
    "    color = cat_colors.get(cat, \"black\")\n",
    "    ax.plot(MULTIPLIERS, yes_rates, \"o-\", label=cat, color=color, linewidth=2, markersize=6)\n",
    "\n",
    "ax.axhline(0.5, color=\"grey\", linestyle=\"--\", alpha=0.5, label=\"chance\")\n",
    "ax.axvline(0, color=\"grey\", linestyle=\":\", alpha=0.3)\n",
    "\n",
    "ax.set_xlabel(\"Steering multiplier\")\n",
    "ax.set_ylabel(\"Fraction 'yes' (refers to me)\")\n",
    "ax.set_title(\"Self-Reference Threshold Curves by Category\")\n",
    "ax.legend(fontsize=8, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "ax.set_xticks(MULTIPLIERS)\n",
    "ax.set_xticklabels([f\"{m:+d}\" for m in MULTIPLIERS])\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/steering_threshold_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved to figures/steering_threshold_curves.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key questions this experiment answers:\n",
    "\n",
    "1. **Which categories are firmly self-referential?** (stay \"yes\" into negative steering)\n",
    "2. **Which are firmly other-referential?** (stay \"no\" into positive steering)\n",
    "3. **Where is the decision boundary?** (which sentences flip, and at what multiplier?)\n",
    "4. **Does the ordering match geometric predictions?** (do projection distances\n",
    "   onto the self-axis predict behavioral thresholds?)\n",
    "5. **Does roleplay-as-AI flip before grounded self-description?** (earlier finding:\n",
    "   \"robot\" scored more self-relevant than default assistant)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=== Threshold Summary ===\\n\")\n",
    "\n",
    "for cat in test_sentences:\n",
    "    print(f\"\\n{cat}:\")\n",
    "    for sent in test_sentences[cat]:\n",
    "        responses = [results[cat][sent][m] for m in MULTIPLIERS]\n",
    "        labels = [f\"{m:+d}:{r}\" for m, r in zip(MULTIPLIERS, responses)]\n",
    "        # Find flip point (first transition from no->yes or yes->no)\n",
    "        flips = []\n",
    "        for i in range(1, len(responses)):\n",
    "            if responses[i] != responses[i-1]:\n",
    "                flips.append(f\"{MULTIPLIERS[i-1]:+d}\\u2192{MULTIPLIERS[i]:+d}\")\n",
    "        flip_str = f\"  flips at: {', '.join(flips)}\" if flips else \"  (stable)\"\n",
    "        print(f\"  {sent[:60]}\")\n",
    "        print(f\"    {' | '.join(labels)}\")\n",
    "        print(f\"    {flip_str}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}